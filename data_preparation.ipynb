{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6347149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d6d259",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "61fb99db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d68efd",
   "metadata": {},
   "source": [
    "Columns\n",
    "\n",
    "- `id` - a unique identifier for each tweet\n",
    "- `keyword` - a particular keyword from the tweet (may be blank) (can be null)\n",
    "- `location` - the location the tweet was sent from (may be blank) (can be null)\n",
    "- `text` - the text of the tweet\n",
    "- `target` - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc71b70",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b614ebf0",
   "metadata": {},
   "source": [
    "people use angle brackets `< >` to indicate emotions\n",
    "\n",
    "=> covert text like `&lt;gasp!&gt;` to `<gasp!>` (could give the model an idea of the sentiment in the text)\n",
    "\n",
    "there are also some html encodings applied multiple times `House Energy &amp;amp; Commerce`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "eaebc526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines converted:  359\n",
      "lines converted:  6\n",
      "lines converted:  0\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    converted_text = df[\"text\"].apply(html.unescape)\n",
    "    cnt = (converted_text != df[\"text\"]).sum()\n",
    "    print(\"lines converted: \", cnt)\n",
    "\n",
    "    if cnt == 0:\n",
    "        break\n",
    "\n",
    "    df[\"text\"] = converted_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d16d53",
   "metadata": {},
   "source": [
    "convert emojis in __text descriptors__ (`:emoji:`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8276bc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines converted:  10\n"
     ]
    }
   ],
   "source": [
    "converted_text = df[\"text\"].apply(emoji.demojize)# use line 2066 for html example\n",
    "\n",
    "print(\"lines converted: \", (converted_text != df[\"text\"]).sum())\n",
    "\n",
    "df[\"text\"] = converted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69603600",
   "metadata": {},
   "source": [
    "`t.co` is the __URL shortener service__ used by Twitter to shorten all links shared on its platform\n",
    "\n",
    "does not provide a meaningfull information since the link is build like `http://t.co/*id*` => make a token for the link (preserves the context of a link existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "15ff5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].replace(r\"http\\S+\", \"<LINK>\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90838465",
   "metadata": {},
   "source": [
    "reduce the mentions but __keep the context of a mention__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "2005f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].replace(r\"@\\S+\", \"<MENTION>\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7bded0",
   "metadata": {},
   "source": [
    "remove duplicates after tokanization (`<LINK>`s or `<MENTION>`s, might replace distinct values, but the overall text is the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "efa466e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated:  653\n",
      "df size:  38065\n",
      "duplicated:  0\n",
      "df size:  34800\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates and remove them\n",
    "print(\"duplicated: \", df[\"text\"].duplicated().sum())\n",
    "print(\"df size: \", df.size)\n",
    "df = df.drop_duplicates(subset=[\"text\"])\n",
    "print(\"duplicated: \", df[\"text\"].duplicated().sum())\n",
    "print(\"df size: \", df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f842e0d",
   "metadata": {},
   "source": [
    "remove multiple spaces and new lines (less noise for classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b178053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac36bd",
   "metadata": {},
   "source": [
    "there are still some encodings from the original text that are corrupted: `... Taiwan ÛÒ ...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6ba7ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].str.encode('ascii', 'ignore').str.decode('ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acba42e",
   "metadata": {},
   "source": [
    "remove the URL encoding for a space character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3495e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keyword'] = df['keyword'].str.replace('%20', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "da165568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"location\"].to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7032402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true instnces: 2855 (41.020114942528735)\n",
      "false instnces: 4105 (58.97988505747126)\n"
     ]
    }
   ],
   "source": [
    "total = len(df)\n",
    "true_count = (df[\"target\"] == 1).sum()\n",
    "false_count = (df[\"target\"] == 0).sum()\n",
    "\n",
    "print(\"true instnces: {} ({})\".format(true_count, true_count/total*100))\n",
    "print(\"false instnces: {} ({})\".format(false_count, false_count/total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f1fa70",
   "metadata": {},
   "source": [
    "conclusion => the dataset is somewhat balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "178b80d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique keywords:  221\n",
      "in average, 31.25 instances per keyword\n"
     ]
    }
   ],
   "source": [
    "count_per_location = df.groupby(\"keyword\")[\"id\"].count()\n",
    "print(\"unique keywords: \", count_per_location.size)\n",
    "print(\"in average, {:.2f} instances per keyword\".format(count_per_location.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "eab8bf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fatalities</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deluge</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>armageddon</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>damage</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body bags</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hijacking</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epicentre</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inundation</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radiation emergency</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     target\n",
       "keyword                    \n",
       "fatalities               45\n",
       "deluge                   42\n",
       "armageddon               42\n",
       "damage                   41\n",
       "body bags                41\n",
       "...                     ...\n",
       "hijacking                13\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation emergency       9\n",
       "\n",
       "[221 rows x 1 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"keyword\")[[\"target\"]].count().sort_values(\"target\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ecd511",
   "metadata": {},
   "source": [
    "conclusion => some keywords may hint the tweet is disaster because they have more true instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "67bb61b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique locations:  3195\n",
      "in average, 1.46 instances per location\n"
     ]
    }
   ],
   "source": [
    "count_per_location = df.groupby(\"location\")[\"id\"].count()\n",
    "print(\"unique locations: \", count_per_location.size)\n",
    "print(\"in average, {:.2f} instances per location\".format(count_per_location.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7bdac9",
   "metadata": {},
   "source": [
    "conclusion => location is not really relevant in determining if the tweet is disaster or not (many locations are invented or self-typed, not really a relevant conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f3d39f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"train_prepared.csv\", index=False, columns=[\"id\", \"keyword\", \"text\", \"target\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
