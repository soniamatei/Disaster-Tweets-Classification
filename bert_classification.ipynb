{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# use gpu for training\n",
    "# set before pytorch loads\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EvalPrediction\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc8a82",
   "metadata": {},
   "source": [
    "## Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6228984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_prepared.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e7ac8c",
   "metadata": {},
   "source": [
    "Split the data so that we have an equl ratio of `target` variables in both test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], \n",
    "    df['target'],\n",
    "    test_size=0.2,\n",
    "    stratify=df['target'],  # keep the ratio equal for test and train splits\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# check if the split maintained the distribution\n",
    "print(\"train distribution:\")\n",
    "print(\"true:  {}%\".format((y_train == 1).sum()/len(y_train)*100))\n",
    "print(\"false: {}%\".format((y_train == 0).sum()/len(y_train)*100))\n",
    "print(\"\\ntest distribution:\")\n",
    "print(\"true:  {}%\".format((y_test == 1).sum()/len(y_test)*100))\n",
    "print(\"false: {}%\".format((y_test == 0).sum()/len(y_test)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd3f47",
   "metadata": {},
   "source": [
    "## Retrieve the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc5f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"vinai/bertweet-base\"\n",
    "# take the specialized tokenizer for the model pretrained\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# take the moodel, pretrained, with a fresh last layer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2) # number of output labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad71b9b9",
   "metadata": {},
   "source": [
    "## Input Preparation\n",
    "\n",
    "Convert the data into the format that the BerTweet is familiar with. \n",
    "Because Bert is a Neural Network, it operates on numbers, so we have to creeate number representations for each sentence:\n",
    "- separate the sentences on words\n",
    "- apply tokens like [CLS] \n",
    "- map words to word id (based on learned vocabulary)\n",
    "- apply padding and trucation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b6ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'text': X_train.tolist(),   \n",
    "    'label': y_train.tolist()   \n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'text': X_test.tolist(),\n",
    "    'label': y_test.tolist()\n",
    "})\n",
    "\n",
    "# padding='max_length' -> apply padding so that training can be done on batches\n",
    "# truncation=True -> for the specially long tweets, truncare them\n",
    "# max_length=128 -> majority of tweets have from 50-80 words\n",
    "train_dataset = train_dataset.map(lambda x: tokenizer(x[\"text\"], padding='max_length', truncation=True, max_length=128), batched=True)\n",
    "test_dataset = test_dataset.map(lambda x: tokenizer(x[\"text\"], padding='max_length', truncation=True, max_length=128), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6870b876",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee883a39",
   "metadata": {},
   "source": [
    "Create a metrics function which will output the training progress. We care about metrics that are more suitable for imabalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac332faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred: EvalPrediction) -> dict:\n",
    "    # predictions = [[percentage_0_class_elem_1, percentage_1_class_elem_1], ...]\n",
    "    # labels = [true_label_elem_1, true_label_elem_2, ...]\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # get the position of the bigger percentage (class 0 or 1); axis=1 -> per element\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='binary' # treat the labels together as a binary class, not separate\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bccb22",
   "metadata": {},
   "source": [
    "Use the transformers training algorithm to train the Bertweet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e40cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    # BERTWEET-SPECIFIC: Higher learning rate works well for BERTweet on tweets\n",
    "    learning_rate=3e-5,  # BERTweet paper suggests 2e-5 to 5e-5, we use 3e-5\n",
    "    num_train_epochs=4,\n",
    "    # BERTWEET-SPECIFIC\n",
    "    per_device_train_batch_size=32,  # tweets are short, so batch can be bigger \n",
    "    per_device_eval_batch_size=32,\n",
    "    # BERTWEET-SPECIFIC\n",
    "    weight_decay=0.01, # avoid having too large weights\n",
    "    # BERTWEET-SPECIFIC\n",
    "    warmup_steps=500,  # gradually increase learning rate at start -> prevents unstable/chaotic updates in early training when model hasn't learned patterns \n",
    "    # BERTWEET-SPECIFIC: \n",
    "    max_grad_norm=1.0,  # prevents huge adjustments to the weights (exploding gradients)\n",
    "    eval_strategy=\"epoch\", # evaluate the model after each epoch\n",
    "    save_strategy=\"epoch\", # don't save the model in a file\n",
    "    output_dir='./temp_checkpoints',  # save models for loading comparison (otherwise last is returned)\n",
    "    load_best_model_at_end=True, # load the best model after evaluations in variable\n",
    "    metric_for_best_model='f1',  # better for slightly imbalaned data like ours (measuring precision and recall)\n",
    "    # BERTWEET-SPECIFIC\n",
    "    optim='adamw_torch',\n",
    ")\n",
    "\n",
    "# trainer api specialized for hugging face transformers\n",
    "trainer = Trainer(\n",
    "    model=model,                    \n",
    "    args=training_args,             \n",
    "    train_dataset=train_dataset,    \n",
    "    eval_dataset=test_dataset,      \n",
    "    compute_metrics=compute_metrics \n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a5aa9",
   "metadata": {},
   "source": [
    "Save the best model after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./final_bertweet_model')\n",
    "tokenizer.save_pretrained('./final_bertweet_tokenizer_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2271a70",
   "metadata": {},
   "source": [
    "Optionally, load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = AutoModelForSequenceClassification.from_pretrained('./final_bertweet_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('./final_bertweet_tokenizer_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
